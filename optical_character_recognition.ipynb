{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setting GPU"
      ],
      "metadata": {
        "id": "jxOKBkLS9QZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9IV-PIzQnuR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'We are training on {device} for this experiment')\n",
        "assert 'cuda' in repr(device),'GPU is not selected in hardware accelerator dropdown '"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HqalkWUpQxSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_google_drive_path = \"/content/drive/MyDrive/checkpoints/\"\n",
        "import os\n",
        "assert os.path.isdir(your_google_drive_path), f\"{your_google_drive_path} is not a valid location\""
      ],
      "metadata": {
        "id": "X4m63i5rSM3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "BidmBwP9SPqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ilCGWSHK9jor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "#Get dataset class object corresponding to train split\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "#Create data loader from train dataset object\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "#Get dataset class object corresponding to test split\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "#Create data loader from test dataset object\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('0','1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "metadata": {
        "id": "623Iugj3SSkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "demalJxJSTcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3,padding= 1)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3,padding= 1)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 3,padding= 1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, padding= 1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3,padding= 1)\n",
        "        self.conv6 = nn.Conv2d(256,512, 3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(512, 512, 3,padding= 1)\n",
        "        self.fc1 = nn.Linear(512, 10)\n",
        "        self.temp = nn.Conv2d(128, 512, 3, padding= 1)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        y = x\n",
        "        x = F.relu(self.bn2(self.conv3(x)))\n",
        "        x = F.relu(self.bn2(self.conv4(x)))\n",
        "        z= self.temp(x)\n",
        "        x = F.relu(self.bn3(self.conv5(x + y)))  # Add y before pooling\n",
        "        x = F.relu(self.bn4(self.conv6(x)))\n",
        "        y = x\n",
        "        x = F.relu(self.bn4(self.conv7(x + z)))  # Add z before convolution\n",
        "        x = F.relu(self.bn4(self.conv8(x)))\n",
        "        x = F.adaptive_avg_pool2d(x + y, (1, 1))  # Add y before pooling\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "aG11M72NSczu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "HAmG_NqMSfrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validator(testloader=None,net=None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            # perform max along dimension 1, since dimension 0 is batch dimension\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "vM6FltUiSmCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch=0\n",
        "end_epoch=10"
      ],
      "metadata": {
        "id": "Gm1ixLnZSooU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = -1.0\n",
        "for epoch in range(start_epoch,end_epoch):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate( trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    current_accuracy = validator(testloader=testloader,net=net)\n",
        "    if current_accuracy>best_accuracy:\n",
        "        best_accuracy = current_accuracy\n",
        "\n",
        "        torch.save(\n",
        "            {'epoch':epoch,\n",
        "             'model_state_dict': net.state_dict(),\n",
        "             'optimizer_state_dict': optimizer.state_dict()\n",
        "             },\n",
        "\n",
        "             your_google_drive_path+'best_model.pth')\n",
        "    #Save model as checkpoint\n",
        "    torch.save(\n",
        "        {'epoch':epoch,\n",
        "         'model_state_dict': net.state_dict(),\n",
        "         'optimizer_state_dict': optimizer.state_dict()\n",
        "         },\n",
        "         your_google_drive_path+'checkpoint.pth')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "6ZMxDHOmSsXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "plt.subplots(figsize=(2,4))\n",
        "# print images\n",
        "plt.imshow(torchvision.utils.make_grid(images[:8],nrow=2).permute(1,2,0))\n",
        "plt.show()\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))"
      ],
      "metadata": {
        "id": "C7yeNA1NSx9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_best = Net().to(device)\n",
        "checkpoint = torch.load(your_google_drive_path+'best_model.pth')\n",
        "net_best.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = net_best(images)"
      ],
      "metadata": {
        "id": "Rf_zJRf_TH4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
        "print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))\n"
      ],
      "metadata": {
        "id": "TB8nKA1hTKf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Native Dataset"
      ],
      "metadata": {
        "id": "kYroswKwklah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_folder, transform=None):\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self.classes = os.listdir(data_folder)\n",
        "        self.data = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        data = []\n",
        "        for i, class_folder in enumerate(self.classes):\n",
        "            class_path = os.path.join(self.data_folder, class_folder)\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                data.append((img_path, i))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "ItkzFd9hTXXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_1 = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "data=CustomDataset(data_folder=\"/content/drive/MyDrive/HINDI_NUMERALS/\",transform=transform_1)"
      ],
      "metadata": {
        "id": "J0usEUGeTbwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "21bd85f8-3c4e-4f06-9c51-5730e28300c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-308d9c580e20>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform_1 = transforms.Compose(\n\u001b[0m\u001b[1;32m      2\u001b[0m     [transforms.ToTensor(),\n\u001b[1;32m      3\u001b[0m      transforms.Normalize((0.5), (0.5))])\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/HINDI_NUMERALS/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "batch_size=8\n",
        "# Randomly split the dataset into train and test sets\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
        "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "classes = data.classes\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter) #4 images will be there since batch size is 4, images have [batch,channel,heigh,width]\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))"
      ],
      "metadata": {
        "id": "Ghr2d3wITg-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch=0\n",
        "end_epoch=10"
      ],
      "metadata": {
        "id": "af3hVCkMT9Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del inputs,images,labels,loss,optimizer"
      ],
      "metadata": {
        "id": "bqk-hsyulXiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1=Net().to(device)"
      ],
      "metadata": {
        "id": "leye7JUAltWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "lToTpORVom-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = -1.0\n",
        "for epoch in range(start_epoch,end_epoch):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate( trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net1(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    current_accuracy = validator(testloader=testloader,net=net1)\n",
        "    if current_accuracy>best_accuracy:\n",
        "        best_accuracy = current_accuracy\n",
        "\n",
        "        torch.save(\n",
        "            {'epoch':epoch,\n",
        "             'model_state_dict': net1.state_dict(),\n",
        "             'optimizer_state_dict': optimizer.state_dict()\n",
        "             },\n",
        "\n",
        "             your_google_drive_path+'hindi_best_model.pth')\n",
        "\n",
        "    #Save model as checkpoint\n",
        "    torch.save(\n",
        "        {'epoch':epoch,\n",
        "         'model_state_dict': net1.state_dict(),\n",
        "         'optimizer_state_dict': optimizer.state_dict()\n",
        "         },\n",
        "         your_google_drive_path+'hindi_checkpoint.pth')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "bg2hnbrOUBCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))"
      ],
      "metadata": {
        "id": "4nivaaU2UH2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_best = Net().to(device)\n",
        "checkpoint = torch.load(your_google_drive_path+'hindi_best_model.pth')\n",
        "net_best.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = net_best(images)"
      ],
      "metadata": {
        "id": "UuD70YRpULLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
        "print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))"
      ],
      "metadata": {
        "id": "3OC_-k-YUPqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model using Fine Tuning\n",
        "Initial weights are taken from classification model of  MNIST Model"
      ],
      "metadata": {
        "id": "k5mNP1T391wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2=Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)\n",
        "checkpoint = torch.load(your_google_drive_path+'best_model.pth')\n",
        "start_epoch = checkpoint['epoch']+1\n",
        "net2.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "TWY9KB00UgXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set requires_grad for all layers except last two as False"
      ],
      "metadata": {
        "id": "HYYoI8F3-cyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in net2.parameters():\n",
        "    param.requires_grad = False\n",
        "# Unfreeze the last few layers\n",
        "for param in net2.fc1.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "jO4WXLmJUmUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "M-jC5kkA5kw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del loss"
      ],
      "metadata": {
        "id": "S6-Zjf2Ft3eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch=0\n",
        "best_accuracy = -1.0\n",
        "for epoch in range(start_epoch,end_epoch):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate( trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    current_accuracy = validator(testloader=testloader,net=net2)\n",
        "    if current_accuracy>best_accuracy:\n",
        "        best_accuracy = current_accuracy\n",
        "\n",
        "        torch.save(\n",
        "            {'epoch':epoch,\n",
        "             'model_state_dict': net2.state_dict(),\n",
        "             'optimizer_state_dict': optimizer.state_dict()\n",
        "             },\n",
        "\n",
        "             your_google_drive_path+'hindi_ft_best_model.pth')\n",
        "\n",
        "    #Save model as checkpoint\n",
        "    torch.save(\n",
        "        {'epoch':epoch,\n",
        "         'model_state_dict': net2.state_dict(),\n",
        "         'optimizer_state_dict': optimizer.state_dict()\n",
        "         },\n",
        "         your_google_drive_path+'hindi_finetuned_checkpoint.pth')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "12f_uGJRWhnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ground Truth"
      ],
      "metadata": {
        "id": "gftNB9S2-toa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "ePJ5-nJhWwaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the above images using above"
      ],
      "metadata": {
        "id": "CXsFAK1O-wun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net_best = Net().to(device)\n",
        "checkpoint = torch.load(your_google_drive_path+'hindi_ft_best_model.pth')\n",
        "net_best.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = net_best(images)"
      ],
      "metadata": {
        "id": "IrZd4NfNW0B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "WBtuhS7BW6Nc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}